<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Removing Diffraction Image Artifacts in Under-Display Camera</title>
  <!--=================Meta tags==========================-->
  <meta name="robots" content="index,follow">
  <meta name="keywords" content="image restoration, UDC">
  <link rel="author" href="https://jnjaby.github.io/projects/UDC">
  <!--=================js==========================-->
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link href="./css.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" type="text/css" href="../project.css" media="screen">
  <script src="./effect.js "></script>
  <!-- Latex -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      });
      </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
    </script>
  <!--=================Google Analytics==========================-->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-129775907-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-129775907-1');
  </script>
</head>

<body>
  <div id="content">
    <div id="content-inner">
      <div class="section head">
        <h1>
          Removing Diffraction Image Artifacts in Under-Display 
        </h1>
        <h1>
          Camera via Dynamic Skip Connection Networks
        </h1>
        <!--=================Authors==========================-->
        <div class="authors">
          <a href="https://jnjaby.github.io/" target="_blank">Ruicheng Feng</a> <sup>1</sup>
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://li-chongyi.github.io/" target="_blank">Chongyi Li</a> <sup>1</sup>
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://hc25.web.rice.edu/" target="_blank">Huaijin Chen</a> <sup>2</sup>
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://scholar.google.com/citations?user=mFG5Sv4AAAAJ&hl=en/" target="_blank">Shuai Li</a> <sup>2</sup>
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://personal.ie.cuhk.edu.hk/~ccloy/" target="_blank">
            Chen Change Loy</a> <sup>1</sup>
            &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://www.gujinwei.org/" target="_blank">Jinwei Gu</a> <sup>2,3</sup>
        </div>

        <div class="affiliations ">
          <sup>1</sup> S-Lab, Nanyang Technological University<br>
          <sup>2</sup> Tetras.AI<br>
          <sup>3</sup> Shanghai AI Laboratory
        </div>
        <!--=================Tabs==========================-->
        <ul id="tabs">
          <li><a href="#abstract" name="#tab1">Abstract</a></li>
          <li><a href="#materials" name="#tab2">Materials</a></li>
          <li><a href="#citation" name="#tab3">Citation</a></li>
      </div>
      <br>
      <!--=================Teasers==========================-->
      <div class="container">
        <div>
          <table width="90%" align="center" cellspacing="0" cellpadding="30px">
            <tbody><tr>
          <td style="padding:0 10px 10px 10px;">
            <img src="src/syn_LQ1.png" onmouseover="this.src='src/syn_GT1.png';" onmouseout="this.src='src/syn_LQ1.png';" height="280" width="280">
          </td>
          <td style="padding:0 10px 10px 10px;">
            <img src="src/syn_LQ2.png" onmouseover="this.src='src/syn_GT2.png';" onmouseout="this.src='src/syn_LQ2.png';" height="280" width="280">
          </td>
          <td style="padding:0 10px 10px 10px;">	
            <img src="src/syn_LQ3.png" onmouseover="this.src='src/syn_GT3.png';" onmouseout="this.src='src/syn_LQ3.png';" height="280" width="280">
          </td></tr>
          <tr>
          <td style="padding:0 10px 10px 10px;">			  
            <img src="src/syn_LQ4.png" onmouseover="this.src='src/syn_GT4.png';" onmouseout="this.src='src/syn_LQ4.png';" height="280" width="280">
          </td>	  
          <td style="padding:0 10px 10px 10px;">			  
            <img src="src/syn_LQ5.png" onmouseover="this.src='src/syn_GT5.png';" onmouseout="this.src='src/syn_LQ5.png';" height="280" width="280">
          </td>
          <td style="padding:0 10px 10px 10px;">			  
            <img src="src/syn_LQ6.png" onmouseover="this.src='src/syn_GT6.png';" onmouseout="this.src='src/syn_LQ6.png';" height="280" width="280">
          </td>
          </tr>	  
          
        </tbody></table>
        </div>
      </div>

      <!--=================Abstract==========================-->
      <div class="section abstract", id="abstract">
        <h2>Abstract</h2>
        <p>
          <br>
          Recent development of Under-Display Camera (UDC) systems provides a true bezel-less and notch-free viewing experience on smartphones (and TV, laptops, tablets), while allowing images to be captured from the selfie camera embedded underneath. In a typical UDC system, the microstructure of the semi-transparent organic light-emitting
          diode (OLED) pixel array attenuates and diffracts the incident
          light on the camera, resulting in significant image
          quality degradation. Often times, noise, flare, haze, and
          blur can be observed in UDC images. In this work, we aim
          to analyze and tackle the aforementioned degradation problems.
          We define a physics-based image formation model to
          better understand the degradation. In addition, we utilize
          one of the worldâ€™s first commodity UDC smartphone prototypes
          to measure the real-world Point Spread Function
          (PSF) of the UDC system, and provide a model-based data
          synthesis pipeline to generate realistically degraded images.
          We specially design a new domain knowledge-enabled
          Dynamic Skip Connection Network (DISCNet) to restore
          the UDC images. We demonstrate the effectiveness of our
          method through extensive experiments on both synthetic and
          real UDC data. Our physics-based image formation model and proposed DISCNet can provide foundations for further exploration in UDC image restoration, and even for general diffraction artifact removal in a broader sense.
        </p>
        <div style="text-align: center; vertical-align:middle">
          <img src="src/schematic.png" width="880">
        </div>
      </div>

      <!--=================Materials==========================-->
      <div class="section materials" , id="materials">
        <h2>Materials</h2>
        <table width="100%" align="center" border=none cellspacing="0" cellpadding="30">
          <tr>
            <td width="30%">
              <center>
                <a href="https://jnjaby.github.io/projects/UDC/src/03719.pdf" target="_blank" class="imageLink"><img
                    src="./src/thumbnail.png" , height="120"></a><br>
                <a href="https://jnjaby.github.io/projects/UDC" disabled target="_blank">Paper</a>
              </center>
            </td>
            <td width="30%">
              <center>
                <a href="https://jnjaby.github.io/projects/UDC" target="_blank" class="imageLink"><img
                    src="../icon_dataset.png" , height="120"></a><br>
                <a href="https://jnjaby.github.io/projects/UDC" target="_blank">Data</a>
              </center>
            </td>
            <td width="30%" valign="middle">
              <center>
                <a href="https://jnjaby.github.io/projects/UDC" target="_blank" class="imageLink"><img
                    src="../icon_github.png" , height="120"></a><br>
                <a href="https://jnjaby.github.io/projects/UDC" target="_blank">Codes (coming soon)</a>
              </center>
            </td>
          </tr>
        </table>
      </div>
    </div>

      <!--=================Dataset==========================-->
      <div class="section" , id="Dataset">
        <h2>Dataset</h2>
        <p>
          We provide both the synthetic and real dataset for Under-Display Camera Images. Train and validation subsets are publicly available. Downloads are available via Google Drive or running the python code. The released dataset can only be used for research purposes.
        </p>
        <p>
          For synthetic data, we gather 2016 HDR patches of size [800, 800, 3] for training and 360 pairs for testing. Since these patches are reprojected and cropped from the 360-degree panorama, they may exhibit some overlap contents (but in different perspective view). Image values are ranging from [0, 500] and constructed in '.npy' form. For each of the crops, we release the ground-truth iamges and you can simulate the corresponding degraded image with calibrated PSFs by running the code. 
        </p>
        <p>
          For real data, we release 30 HDR images of size [3264, 2448, 3] using ZTE phone. Similarly, image values are ranging from [0, 16] and constructed in '.npy' form. Images are in linear domain and are not processed by the built-in ISP of the phone. We provide a simple pipeline of post-processing for better visulization. The camera output of the phone (after ISP) are also released for reference and color correction pipeline.
        </p>
      </div>


      <!--=================Citation==========================-->
      <div class="section citation" , id="citation">
        <h2>Citation</h2>
        If you find our dataset and paper useful for your research, please consider citing our work:
        <div class="section bibtex">
          <pre>@inproceedings{feng2021removing,
          author = {Feng, Ruicheng and Li, Chongyi and Chen, Huaijin and Li, Shuai and Loy, Chen Change and Gu, Jinwei},
          title = {Removing Diffraction Image Artifacts in Under-Display Camera via Dynamic Skip Connection Networks},
          booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
          year = {2021}
          }
          </pre>
        </div>
      </div>

      <!--=================Contact==========================-->
      <div class="section contact">
        <h2 id="contact">Contact</h2>
        <p>If you have any question, please contact us via <strong>ruicheng002@ntu.edu.sg</strong>.
        </p>
        <br>
      </div>
</body>

</html>